{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1-BigData-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WmxmOcZ8PZP",
        "colab_type": "text"
      },
      "source": [
        "# Load Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAFAxhIA0XGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install latest version of spark. If error, check the latest and replace \"spark-2.4.4\"\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3tyCqfk3obe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The entry point to using Spark SQL is an object called SparkSession. \n",
        "#It initiates a Spark Application which all the code for that Session will run on.\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"Learning_Spark\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A0teo3t1jRQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "812a8d59-23d1-49c6-91b0-87f9f589c021"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeVelwW58TUO",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nQBISFE1nvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = \"/content/gdrive/My Drive/BigData/q1/adult_data.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zbVkMdi3rgF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "eb8c887f-4167-40bc-84fc-4ada10ae0488"
      },
      "source": [
        "data = spark.read.csv(DATA_PATH,inferSchema=True, header=False)\n",
        "print(data.count(),len(data.columns))\n",
        "data.show(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32561 15\n",
            "+---+-----------------+--------+----------+----+-------------------+------------------+--------------+------+-------+------+----+----+--------------+------+\n",
            "|_c0|              _c1|     _c2|       _c3| _c4|                _c5|               _c6|           _c7|   _c8|    _c9|  _c10|_c11|_c12|          _c13|  _c14|\n",
            "+---+-----------------+--------+----------+----+-------------------+------------------+--------------+------+-------+------+----+----+--------------+------+\n",
            "| 39|        State-gov| 77516.0| Bachelors|13.0|      Never-married|      Adm-clerical| Not-in-family| White|   Male|2174.0| 0.0|40.0| United-States| <=50K|\n",
            "| 50| Self-emp-not-inc| 83311.0| Bachelors|13.0| Married-civ-spouse|   Exec-managerial|       Husband| White|   Male|   0.0| 0.0|13.0| United-States| <=50K|\n",
            "| 38|          Private|215646.0|   HS-grad| 9.0|           Divorced| Handlers-cleaners| Not-in-family| White|   Male|   0.0| 0.0|40.0| United-States| <=50K|\n",
            "| 53|          Private|234721.0|      11th| 7.0| Married-civ-spouse| Handlers-cleaners|       Husband| Black|   Male|   0.0| 0.0|40.0| United-States| <=50K|\n",
            "| 28|          Private|338409.0| Bachelors|13.0| Married-civ-spouse|    Prof-specialty|          Wife| Black| Female|   0.0| 0.0|40.0|          Cuba| <=50K|\n",
            "+---+-----------------+--------+----------+----+-------------------+------------------+--------------+------+-------+------+----+----+--------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10_zHacC6P_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "117e5fa6-407f-436a-f80b-bc24b7a307e1"
      },
      "source": [
        "col_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\", \n",
        "             \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\", \n",
        "             \"hours_per_week\", \"native_country\", \"income\"]\n",
        "print(len(col_names))\n",
        "data = data.toDF(*col_names)\n",
        "data.show(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "+---+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
            "|age|        workclass|  fnlwgt| education|education_num|     marital_status|        occupation|  relationship|  race|    sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n",
            "+---+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
            "| 39|        State-gov| 77516.0| Bachelors|         13.0|      Never-married|      Adm-clerical| Not-in-family| White|   Male|      2174.0|         0.0|          40.0| United-States| <=50K|\n",
            "| 50| Self-emp-not-inc| 83311.0| Bachelors|         13.0| Married-civ-spouse|   Exec-managerial|       Husband| White|   Male|         0.0|         0.0|          13.0| United-States| <=50K|\n",
            "| 38|          Private|215646.0|   HS-grad|          9.0|           Divorced| Handlers-cleaners| Not-in-family| White|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
            "| 53|          Private|234721.0|      11th|          7.0| Married-civ-spouse| Handlers-cleaners|       Husband| Black|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
            "| 28|          Private|338409.0| Bachelors|         13.0| Married-civ-spouse|    Prof-specialty|          Wife| Black| Female|         0.0|         0.0|          40.0|          Cuba| <=50K|\n",
            "+---+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wqFpZ6x8VXC",
        "colab_type": "text"
      },
      "source": [
        "# 2. Data preprocessing\n",
        "用ML Pipelines 和Feature Transformers 将categorical variables into numeric variables 。可能用到OneHotEncoderEstimator, StringIndexer, 和 VectorAssembler。将数据分成training set and test setwith ratio of 70% and 30% and set the seed to 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfb6ZIjW8dA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dez_iwcP8YOP",
        "colab_type": "text"
      },
      "source": [
        "# 3. 建模：（10％）\n",
        "用训练集训练逻辑回归模型。在Spark MLlib中了解有关模型提供的更多信息。训练后，绘制训练过程的ROC曲线和Precision-Recall曲线。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu5rxoWl8dE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2h77Us98ge1",
        "colab_type": "text"
      },
      "source": [
        "# 4. 评价：（10％）\n",
        "将模型应用于测试集。提供ROC下的面积值，准确性和混淆矩阵。您应该期望精度在85％。"
      ]
    }
  ]
}