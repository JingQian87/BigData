{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1-BigData-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WmxmOcZ8PZP",
        "colab_type": "text"
      },
      "source": [
        "# Load Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAFAxhIA0XGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install latest version of spark. If error, check the latest and replace \"spark-2.4.4\"\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3tyCqfk3obe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The entry point to using Spark SQL is an object called SparkSession. \n",
        "#It initiates a Spark Application which all the code for that Session will run on.\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"Learning_Spark\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A0teo3t1jRQ",
        "colab_type": "code",
        "outputId": "933f6808-5e44-42f7-8cce-1906e7c2d1d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeVelwW58TUO",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nQBISFE1nvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = \"/content/gdrive/My Drive/BigData/q1/adult_data.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zbVkMdi3rgF",
        "colab_type": "code",
        "outputId": "0039d11b-51c1-44e0-a1fa-bdb08f426c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "data = spark.read.csv(DATA_PATH,inferSchema=True, header=False)\n",
        "print(data.count(),len(data.columns))\n",
        "data.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32561 15\n",
            "+---+-----------------+--------+----------+----+-------------------+------------------+--------------+------+-------+------+----+----+--------------+------+\n",
            "|_c0|              _c1|     _c2|       _c3| _c4|                _c5|               _c6|           _c7|   _c8|    _c9|  _c10|_c11|_c12|          _c13|  _c14|\n",
            "+---+-----------------+--------+----------+----+-------------------+------------------+--------------+------+-------+------+----+----+--------------+------+\n",
            "| 39|        State-gov| 77516.0| Bachelors|13.0|      Never-married|      Adm-clerical| Not-in-family| White|   Male|2174.0| 0.0|40.0| United-States| <=50K|\n",
            "| 50| Self-emp-not-inc| 83311.0| Bachelors|13.0| Married-civ-spouse|   Exec-managerial|       Husband| White|   Male|   0.0| 0.0|13.0| United-States| <=50K|\n",
            "| 38|          Private|215646.0|   HS-grad| 9.0|           Divorced| Handlers-cleaners| Not-in-family| White|   Male|   0.0| 0.0|40.0| United-States| <=50K|\n",
            "| 53|          Private|234721.0|      11th| 7.0| Married-civ-spouse| Handlers-cleaners|       Husband| Black|   Male|   0.0| 0.0|40.0| United-States| <=50K|\n",
            "| 28|          Private|338409.0| Bachelors|13.0| Married-civ-spouse|    Prof-specialty|          Wife| Black| Female|   0.0| 0.0|40.0|          Cuba| <=50K|\n",
            "+---+-----------------+--------+----------+----+-------------------+------------------+--------------+------+-------+------+----+----+--------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10_zHacC6P_h",
        "colab_type": "code",
        "outputId": "0afd653e-0de4-4753-b3a1-3b703afe0789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "col_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\", \n",
        "             \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\", \n",
        "             \"hours_per_week\", \"native_country\", \"income\"]\n",
        "print(len(col_names))\n",
        "data = data.toDF(*col_names)\n",
        "data.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "+---+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
            "|age|        workclass|  fnlwgt| education|education_num|     marital_status|        occupation|  relationship|  race|    sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n",
            "+---+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
            "| 39|        State-gov| 77516.0| Bachelors|         13.0|      Never-married|      Adm-clerical| Not-in-family| White|   Male|      2174.0|         0.0|          40.0| United-States| <=50K|\n",
            "| 50| Self-emp-not-inc| 83311.0| Bachelors|         13.0| Married-civ-spouse|   Exec-managerial|       Husband| White|   Male|         0.0|         0.0|          13.0| United-States| <=50K|\n",
            "| 38|          Private|215646.0|   HS-grad|          9.0|           Divorced| Handlers-cleaners| Not-in-family| White|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
            "| 53|          Private|234721.0|      11th|          7.0| Married-civ-spouse| Handlers-cleaners|       Husband| Black|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
            "| 28|          Private|338409.0| Bachelors|         13.0| Married-civ-spouse|    Prof-specialty|          Wife| Black| Female|         0.0|         0.0|          40.0|          Cuba| <=50K|\n",
            "+---+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6zMuS5P80S3",
        "colab_type": "code",
        "outputId": "2a488a39-8972-4cf1-cbed-b4b109d010c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "data.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- workclass: string (nullable = true)\n",
            " |-- fnlwgt: double (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- education_num: double (nullable = true)\n",
            " |-- marital_status: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- relationship: string (nullable = true)\n",
            " |-- race: string (nullable = true)\n",
            " |-- sex: string (nullable = true)\n",
            " |-- capital_gain: double (nullable = true)\n",
            " |-- capital_loss: double (nullable = true)\n",
            " |-- hours_per_week: double (nullable = true)\n",
            " |-- native_country: string (nullable = true)\n",
            " |-- income: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wqFpZ6x8VXC",
        "colab_type": "text"
      },
      "source": [
        "# 2. Data preprocessing\n",
        "用ML Pipelines 和Feature Transformers 将categorical variables into numeric variables 。可能用到OneHotEncoderEstimator, StringIndexer, 和 VectorAssembler。将数据分成training set and test setwith ratio of 70% and 30% and set the seed to 100.\n",
        "\n",
        "https://towardsdatascience.com/machine-learning-with-pyspark-and-mllib-solving-a-binary-classification-problem-96396065d2aa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOyByqXqDzJa",
        "colab_type": "code",
        "outputId": "1b2d90a1-a8dc-4034-a0ee-96fba71d3317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train, test = data.randomSplit([0.7, 0.3], seed=100)\n",
        "print(\"Training Dataset Count:\", train.count())\n",
        "print(\"Testing Dataset Count:\", test.count())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Dataset Count: 22838\n",
            "Testing Dataset Count: 9723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_vDpBhaB807",
        "colab_type": "code",
        "outputId": "89551f09-ba49-4b88-dcd2-744aa247b87d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"workclass\", outputCol=\"workclassIndex\")\n",
        "inputs = [indexer.getOutputCol()]\n",
        "encoder = OneHotEncoderEstimator(inputCols=inputs, outputCols=[\"workclassVec\"]) \n",
        "pipeline = Pipeline(stages=[indexer, encoder])\n",
        "pipeline.fit(data.select(\"workclass\")).transform(data.select(\"workclass\")).show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+--------------+-------------+\n",
            "|        workclass|workclassIndex| workclassVec|\n",
            "+-----------------+--------------+-------------+\n",
            "|        State-gov|           4.0|(8,[4],[1.0])|\n",
            "| Self-emp-not-inc|           1.0|(8,[1],[1.0])|\n",
            "|          Private|           0.0|(8,[0],[1.0])|\n",
            "|          Private|           0.0|(8,[0],[1.0])|\n",
            "|          Private|           0.0|(8,[0],[1.0])|\n",
            "|          Private|           0.0|(8,[0],[1.0])|\n",
            "|          Private|           0.0|(8,[0],[1.0])|\n",
            "| Self-emp-not-inc|           1.0|(8,[1],[1.0])|\n",
            "|          Private|           0.0|(8,[0],[1.0])|\n",
            "|          Private|           0.0|(8,[0],[1.0])|\n",
            "|          Private|           0.0|(8,[0],[1.0])|\n",
            "|        State-gov|           4.0|(8,[4],[1.0])|\n",
            "|          Private|           0.0|(8,[0],[1.0])|\n",
            "|          Private|           0.0|(8,[0],[1.0])|\n",
            "|          Private|           0.0|(8,[0],[1.0])|\n",
            "|          Private|           0.0|(8,[0],[1.0])|\n",
            "| Self-emp-not-inc|           1.0|(8,[1],[1.0])|\n",
            "|          Private|           0.0|(8,[0],[1.0])|\n",
            "|          Private|           0.0|(8,[0],[1.0])|\n",
            "| Self-emp-not-inc|           1.0|(8,[1],[1.0])|\n",
            "+-----------------+--------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpHPwhB591_z",
        "colab_type": "text"
      },
      "source": [
        "### test class script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfb6ZIjW8dA4",
        "colab_type": "code",
        "outputId": "f47875b8-ae25-4d0d-af9f-a02c1cc03b92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "sentenceDataFrame = spark.createDataFrame([\n",
        "    (0,'Hi I heard about Spark'),\n",
        "    (1, 'I wish'),\n",
        "    (2, 'Logistic, regression-models')\n",
        "], [\"id\", \"sentence\"])\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
        "regexTokenizer = RegexTokenizer(inputCol=\"sentence\", outputCol=\"words\", pattern=\"\\\\W\")\n",
        "\n",
        "countTokens = udf(lambda words: len(words), IntegerType())\n",
        "\n",
        "tokenized = tokenizer.transform(sentenceDataFrame)\n",
        "tokenized.select(\"sentence\",\"words\").withColumn(\"tokens\", countTokens(col(\"words\"))).show(truncate=False)\n",
        "\n",
        "regexTokenized = regexTokenizer.transform(sentenceDataFrame)\n",
        "regexTokenized.select(\"sentence\",\"words\").withColumn(\"tokens\", countTokens(col(\"words\"))).show(truncate=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------+------------------------------+------+\n",
            "|sentence                   |words                         |tokens|\n",
            "+---------------------------+------------------------------+------+\n",
            "|Hi I heard about Spark     |[hi, i, heard, about, spark]  |5     |\n",
            "|I wish                     |[i, wish]                     |2     |\n",
            "|Logistic, regression-models|[logistic,, regression-models]|2     |\n",
            "+---------------------------+------------------------------+------+\n",
            "\n",
            "+---------------------------+------------------------------+------+\n",
            "|sentence                   |words                         |tokens|\n",
            "+---------------------------+------------------------------+------+\n",
            "|Hi I heard about Spark     |[hi, i, heard, about, spark]  |5     |\n",
            "|I wish                     |[i, wish]                     |2     |\n",
            "|Logistic, regression-models|[logistic, regression, models]|3     |\n",
            "+---------------------------+------------------------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqYuKJPEAFTb",
        "colab_type": "code",
        "outputId": "bef076ee-bae4-40f8-a4f0-332028f52533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from pyspark.ml.feature import StopWordsRemover\n",
        "\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "remover.transform(tokenized).show(truncate=False)\n",
        "remover.transform(regexTokenized).show(truncate=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---------------------------+------------------------------+------------------------------+\n",
            "|id |sentence                   |words                         |filtered                      |\n",
            "+---+---------------------------+------------------------------+------------------------------+\n",
            "|0  |Hi I heard about Spark     |[hi, i, heard, about, spark]  |[hi, heard, spark]            |\n",
            "|1  |I wish                     |[i, wish]                     |[wish]                        |\n",
            "|2  |Logistic, regression-models|[logistic,, regression-models]|[logistic,, regression-models]|\n",
            "+---+---------------------------+------------------------------+------------------------------+\n",
            "\n",
            "+---+---------------------------+------------------------------+------------------------------+\n",
            "|id |sentence                   |words                         |filtered                      |\n",
            "+---+---------------------------+------------------------------+------------------------------+\n",
            "|0  |Hi I heard about Spark     |[hi, i, heard, about, spark]  |[hi, heard, spark]            |\n",
            "|1  |I wish                     |[i, wish]                     |[wish]                        |\n",
            "|2  |Logistic, regression-models|[logistic, regression, models]|[logistic, regression, models]|\n",
            "+---+---------------------------+------------------------------+------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfzKFE6h9vXy",
        "colab_type": "text"
      },
      "source": [
        ","
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dez_iwcP8YOP",
        "colab_type": "text"
      },
      "source": [
        "# 3. 建模：（10％）\n",
        "用训练集训练逻辑回归模型。在Spark MLlib中了解有关模型提供的更多信息。训练后，绘制训练过程的ROC曲线和Precision-Recall曲线。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu5rxoWl8dE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2h77Us98ge1",
        "colab_type": "text"
      },
      "source": [
        "# 4. 评价：（10％）\n",
        "将模型应用于测试集。提供ROC下的面积值，准确性和混淆矩阵。您应该期望精度在85％。"
      ]
    }
  ]
}