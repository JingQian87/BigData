{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_BigData_start.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5zLQLgROtt-",
        "colab_type": "text"
      },
      "source": [
        "# Install Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhoQHbVPOb12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install latest version of spark. If error, check the latest and replace \"spark-2.4.4\"\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyfiwjy_Oz-S",
        "colab_type": "code",
        "outputId": "f33a80bc-fe4e-4f53-8793-ea1fab6bf96d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYJ6JeIPPNBL",
        "colab_type": "text"
      },
      "source": [
        "# Part 1. Friendship Recommendation\n",
        "Modify friends.py provided"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrAPrb3fP2cC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "import pyspark\n",
        "import sys\n",
        "from collections import defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O7rO2MhPwJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finished. Return RDD\n",
        "def getData(sc, filename):\n",
        "    \"\"\"\n",
        "    Load data from raw text file into RDD and transform.\n",
        "    Hint: transfromation you will use: map(<lambda function>).\n",
        "    Args:\n",
        "        sc (SparkContext): spark context.\n",
        "        filename (string): hw2.txt cloud storage URI.\n",
        "    Returns:\n",
        "        RDD: RDD list of tuple of (<User>, [friend1, friend2, ... ]),\n",
        "        each user and a list of user's friends\n",
        "    \"\"\"\n",
        "    # read text file into RDD\n",
        "    data = sc.textFile(filename)\n",
        "\n",
        "    # TODO: implement your logic here\n",
        "    data = data.map(lambda line: np.array([str(x) for x in line.split('\\t')]))\n",
        "    data = data.map(lambda p:(int(p[0]), p[1].split(',')))\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IqXGNnTot1l",
        "colab_type": "text"
      },
      "source": [
        "## mapFriends 对间接的启用双向，那直接的需要吗？！还有，会有重复的吗？～"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_EyfieJP6oF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mapFriends(line):\n",
        "    \"\"\"\n",
        "    List out every pair of mutual friends, also record direct friends.\n",
        "    Hint:\n",
        "    For each <User>, record direct friends into a list:\n",
        "    [(<User>, (friend1, 0)),(<User>, (friend2, 0)), ...],\n",
        "    where 0 means <User> and friend are already direct friend,\n",
        "    so you don't need to recommand each other.\n",
        "\n",
        "    For friends in the list, each of them has a friend <User> in common,\n",
        "    so for each of them, record mutual friend in both direction:\n",
        "    (friend1, (friend2, 1)), (friend2, (friend1, 1)),\n",
        "    where 1 means friend1 and friend2 has a mutual friend <User> in this \"line\"\n",
        "\n",
        "    There are possibly multiple output in each input line,\n",
        "    we applied flatMap to flatten them when using this function.\n",
        "    Args:\n",
        "        line (tuple): tuple in data RDD\n",
        "    Yields:\n",
        "        RDD: rdd like a list of (A, (B, 0)) or (A, (C, 1))\n",
        "    \"\"\"\n",
        "    friends = line[1]\n",
        "    user = line[0]\n",
        "    for i in range(len(friends)):\n",
        "        # Direct friend\n",
        "        # TODO: implement your logic here\n",
        "        yield((user,(int(friends[i]),0)))\n",
        "\n",
        "        for j in range(i+1, len(friends)):\n",
        "            # Mutual friend in both direction\n",
        "            # TODO: implement your logic here\n",
        "            yield((int(friends[i]), (int(friends[j]),1)))\n",
        "            yield((int(friends[j]), (int(friends[i]),1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQtBdsRwP9xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def findMutual(line):\n",
        "    \"\"\"\n",
        "    Find top 10 mutual friend for each person.\n",
        "    Hint: For each <User>, input is a list of tuples of friend relations,\n",
        "    whether direct friend (count = 0) or has friend in common (count = 1)\n",
        "\n",
        "    Use friendDict to store the number of mutual friend that the current <User>\n",
        "    has in common with each other <User> in tuple.\n",
        "    Input:(User1, [(User2, 1), (User3, 1), (User2, 1), (User3, 0), (User2, 1)])\n",
        "    friendDict stores: {User2:3, User3:1}\n",
        "    directFriend stores: User3\n",
        "\n",
        "    If a user has many mutual frineds and is not a direct frined, we recommend\n",
        "    them to be friends.\n",
        "\n",
        "    Args:\n",
        "        line (tuple): a tuple of (<User1>, [(<User2>, 0), (<User3>, 1)....])\n",
        "    Returns:\n",
        "        RDD of tuple (line[0], returnList),\n",
        "        returnList is a list of recommended friends\n",
        "    \"\"\"\n",
        "    # friendDict, Key: user, value: count of mutual friends\n",
        "    friendDict = defaultdict(int)\n",
        "    # set of direct friends\n",
        "    directFriend = set()\n",
        "    # initialize return list\n",
        "    returnList = []\n",
        "\n",
        "    # TODO: Iterate through input to aggregate counts\n",
        "    # save to friendDict and directFriend\n",
        "    user = line[0]\n",
        "    friends = line[1]\n",
        "    for i in range(len(friends)):\n",
        "      if friends[i][1] == 0:\n",
        "        directFriend.add(friends[i][0])\n",
        "      else:\n",
        "        friendDict[friends[i][0]] = friendDict.get(friends[i][0],0) + 1\n",
        "        \n",
        "\n",
        "    # TODO: Formulate output\n",
        "\n",
        "\n",
        "    return (line[0], returnList)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lun4wsNJR9cG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def main():\n",
        "# Configure Spark\n",
        "conf = SparkConf()\n",
        "sc = SparkContext.getOrCreate(conf=conf)\n",
        "# The directory for the file\n",
        "filename = \"/content/gdrive/My Drive/BigData/q1.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfk8ZBupTqRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get data in proper format\n",
        "data = getData(sc, filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vITB5ojLTqJp",
        "colab_type": "code",
        "outputId": "03dc1fc4-44bf-42b8-b655-4b357475080c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test mapFriends()\n",
        "# data.flatMap(mapFriends).take(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, (1, 0)), (1, (2, 1)), (2, (1, 1)), (1, (3, 1)), (3, (1, 1))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72xqlRdmTqNZ",
        "colab_type": "code",
        "outputId": "b0ec722e-dd5e-4aa9-b710-3fe45fbfdd05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Get set of all mutual friends\n",
        "mapData = data.flatMap(mapFriends).groupByKey()\n",
        "mapData.take(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('17061', <pyspark.resultiterable.ResultIterable at 0x7f8530d916a0>),\n",
              " ('16643', <pyspark.resultiterable.ResultIterable at 0x7f85313355c0>),\n",
              " ('23869', <pyspark.resultiterable.ResultIterable at 0x7f8530546b38>),\n",
              " ('14871', <pyspark.resultiterable.ResultIterable at 0x7f8530d91400>),\n",
              " ('43832', <pyspark.resultiterable.ResultIterable at 0x7f85304e4b70>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikJtFHNpt7zM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDgIDJPoTJMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# For each person, get top 10 mutual friends\n",
        "getFriends = mapData.map(findMutual)\n",
        "\n",
        "# Only save the ones we want\n",
        "wanted = [924, 8941, 8942, 9019, 49824, 13420, 44410, 8974, 5850, 9993]\n",
        "result = getFriends.filter(lambda x: x[0] in wanted).collect()\n",
        "\n",
        "sc.stop()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}